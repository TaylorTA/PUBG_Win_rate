{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSC2515 Group Project\n",
    "\n",
    "Members: Zhanwen Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def load_df(file_name):\n",
    "    path = os.path.join(file_name)\n",
    "    data_df = pd.read_csv(path)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_df):\n",
    "    #Print data shape\n",
    "    print(\"The dimension of data is {}\".format(data_df.shape))\n",
    "    \n",
    "    #Print column names\n",
    "    print(\"All the columns are listed as follow\")\n",
    "    print(data_df.columns.tolist())\n",
    "    \n",
    "    #Print column types\n",
    "    print(\"The type of each column is:\")\n",
    "    print (data_df.dtypes)\n",
    "    \n",
    "    #Print macth type count\n",
    "    print(\"The count of each match type is:\")\n",
    "    print(data_df.groupby(['matchType']).size())\n",
    "    \n",
    "    #Detect missing values in data\n",
    "    print(\"Is there any missing value in data? Ans: {}\".format(data_df.isna().any().any()))\n",
    "    null_data = data_df[data_df.isna().any(axis=1)]\n",
    "    print(\"The row that has missing value is:\")\n",
    "    print(null_data)\n",
    "    #print(null_data.isna().any())\n",
    "    \n",
    "    #Describe the data\n",
    "    #data_df.describe()\n",
    "\n",
    "    #Calculate the correlation between features\n",
    "    #data_df.corr().style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def preprocess(data_df):\n",
    "    #Drop the three columns: Id, groupId, matchId. Also drop the row with missing value\n",
    "    data_df = data_df.drop(['Id','groupId','matchId'],axis=1).drop([2744604])\n",
    "    print(\"Does the data have missing values now? Ans:{}\".format(data_df.isna().any().any()))\n",
    "\n",
    "    #Delete rows with specific match types\n",
    "    data_df=data_df[data_df['matchType'].isin(['duo','duo-fpp','solo','solo-fpp','squad','squad-fpp'])]\n",
    "    \n",
    "    #Combine match types\n",
    "    data_df[\"matchType\"].replace({\"duo-fpp\":\"duo\", \"solo-fpp\":\"solo\", \"squad-fpp\":\"squad\"}, inplace=True)\n",
    "    \n",
    "    #Count the match types after preprocessing\n",
    "    print(\"After preprocessing, the count of each match type is:\")\n",
    "    print(data_df.groupby(['matchType']).size())\n",
    "    \n",
    "    #Map the macthType column into distinct integers\n",
    "    data_df.matchType = pd.Categorical(data_df.matchType)\n",
    "    print(dict(enumerate(data_df['matchType'].cat.categories)))#Print the mappings\n",
    "    data_df.matchType = data_df.matchType.cat.codes\n",
    "    \n",
    "    #Transform pandas data frame to numpy array\n",
    "    data = np.array(data_df)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data_preprocessed, datasize_per_matchtype):\n",
    "    MATCH_TYPE_INDEX = 12\n",
    "    data_solo = data_preprocessed[data_preprocessed[:,MATCH_TYPE_INDEX] == 0]\n",
    "    data_solo = data_solo[:datasize_per_matchtype]\n",
    "    \n",
    "    data_duo = data_preprocessed[data_preprocessed[:,MATCH_TYPE_INDEX] == 1]\n",
    "    data_duo = data_duo[:datasize_per_matchtype]\n",
    "    \n",
    "    data_squad = data_preprocessed[data_preprocessed[:,MATCH_TYPE_INDEX] == 2]\n",
    "    data_squad = data_squad[:datasize_per_matchtype]\n",
    "    \n",
    "    data_all = np.concatenate((data_solo,data_duo,data_squad))\n",
    "    \n",
    "    X_all = data_all[:,:-1]\n",
    "    y_all = data_all[:,-1]\n",
    "    X_solo = data_solo[:,:-1]\n",
    "    y_solo = data_solo[:,-1]\n",
    "    X_duo = data_duo[:,:-1]\n",
    "    y_duo = data_duo[:,-1]\n",
    "    X_squad = data_squad[:,:-1]\n",
    "    y_squad = data_squad[:,-1]\n",
    "    \n",
    "    return X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common interface to calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "def cal_metrics(y_predict,y_label,model_name):\n",
    "    mae = mean_absolute_error(y_label, y_predict)\n",
    "    mse = mean_squared_error(y_label, y_predict)\n",
    "    rscore = r2_score(y_label, y_predict)\n",
    "    \n",
    "    print(\"Below are metrics for {}\".format(model_name))\n",
    "    print(\"MAE: {}\".format(mae))\n",
    "    print(\"MSE: {}\".format(mse))\n",
    "    print(\"R-Score: {}\".format(rscore))\n",
    "    \n",
    "    return mae, mse, rscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "def train_test_lin_reg(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad):\n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "    lin_reg_all = LinearRegression().fit(X_train_all, y_train_all)\n",
    "    predictions_all = lin_reg_all.predict(X_test_all)\n",
    "    _,_,_ = cal_metrics(predictions_all,y_test_all,\"Linear Regression Model of mixed match type\")\n",
    "\n",
    "    X_train_solo, X_test_solo, y_train_solo, y_test_solo = train_test_split(X_solo, y_solo, test_size=0.2, random_state=42)\n",
    "    lin_reg_solo = LinearRegression().fit(X_train_solo, y_train_solo)\n",
    "    predictions_solo = lin_reg_solo.predict(X_test_solo)\n",
    "    mae_1, mse_1, rscore_1 = cal_metrics(predictions_solo,y_test_solo,\"Linear Regression Model of solo match type\")\n",
    "\n",
    "    X_train_duo, X_test_duo, y_train_duo, y_test_duo = train_test_split(X_duo, y_duo, test_size=0.2, random_state=42)\n",
    "    lin_reg_duo = LinearRegression().fit(X_train_duo, y_train_duo)\n",
    "    predictions_duo = lin_reg_duo.predict(X_test_duo)\n",
    "    mae_2, mse_2, rscore_2 = cal_metrics(predictions_duo,y_test_duo,\"Linear Regression Model of duo match type\")\n",
    "\n",
    "    X_train_squad, X_test_squad, y_train_squad, y_test_squad = train_test_split(X_squad, y_squad, test_size=0.2, random_state=42)\n",
    "    lin_reg_squad = LinearRegression().fit(X_train_squad, y_train_squad)\n",
    "    predictions_squad = lin_reg_squad.predict(X_test_squad)\n",
    "    mae_3, mse_3, rscore_3 = cal_metrics(predictions_squad,y_test_squad,\"Linear Regression Model of squad match type\")\n",
    "    \n",
    "    average_MAE = (mae_1+mae_2+mae_3)/3\n",
    "    average_MSE = (mse_1+mse_2+mse_3)/3\n",
    "    average_rscore = (rscore_1+rscore_2+rscore_3)/3\n",
    "    print(\"Average metrics over 3 sub-models is as follow\")\n",
    "    print(\"Average MAE:{}, Average MSE:{}, Average R-Score:{}\".format(average_MAE,average_MSE,average_rscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest.Please implement and tune\n",
    "#def train_test_random_forest(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network.Please implement and tune\n",
    "#def train_test_nn(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model comparison and draw diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of data is (4446966, 29)\n",
      "All the columns are listed as follow\n",
      "['Id', 'groupId', 'matchId', 'assists', 'boosts', 'damageDealt', 'DBNOs', 'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills', 'killStreaks', 'longestKill', 'matchDuration', 'matchType', 'maxPlace', 'numGroups', 'rankPoints', 'revives', 'rideDistance', 'roadKills', 'swimDistance', 'teamKills', 'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints', 'winPlacePerc']\n",
      "The type of each column is:\n",
      "Id                  object\n",
      "groupId             object\n",
      "matchId             object\n",
      "assists              int64\n",
      "boosts               int64\n",
      "damageDealt        float64\n",
      "DBNOs                int64\n",
      "headshotKills        int64\n",
      "heals                int64\n",
      "killPlace            int64\n",
      "killPoints           int64\n",
      "kills                int64\n",
      "killStreaks          int64\n",
      "longestKill        float64\n",
      "matchDuration        int64\n",
      "matchType           object\n",
      "maxPlace             int64\n",
      "numGroups            int64\n",
      "rankPoints           int64\n",
      "revives              int64\n",
      "rideDistance       float64\n",
      "roadKills            int64\n",
      "swimDistance       float64\n",
      "teamKills            int64\n",
      "vehicleDestroys      int64\n",
      "walkDistance       float64\n",
      "weaponsAcquired      int64\n",
      "winPoints            int64\n",
      "winPlacePerc       float64\n",
      "dtype: object\n",
      "The count of each match type is:\n",
      "matchType\n",
      "crashfpp               6287\n",
      "crashtpp                371\n",
      "duo                  313591\n",
      "duo-fpp              996691\n",
      "flarefpp                718\n",
      "flaretpp               2505\n",
      "normal-duo              199\n",
      "normal-duo-fpp         5489\n",
      "normal-solo             326\n",
      "normal-solo-fpp        1682\n",
      "normal-squad            516\n",
      "normal-squad-fpp      17174\n",
      "solo                 181943\n",
      "solo-fpp             536762\n",
      "squad                626526\n",
      "squad-fpp           1756186\n",
      "dtype: int64\n",
      "Is there any missing value in data? Ans: True\n",
      "The row that has missing value is:\n",
      "                     Id         groupId         matchId  assists  boosts  \\\n",
      "2744604  f70c74418bb064  12dfbede33f92b  224a123c53e008        0       0   \n",
      "\n",
      "         damageDealt  DBNOs  headshotKills  heals  killPlace  ...  revives  \\\n",
      "2744604          0.0      0              0      0          1  ...        0   \n",
      "\n",
      "         rideDistance  roadKills  swimDistance  teamKills vehicleDestroys  \\\n",
      "2744604           0.0          0           0.0          0               0   \n",
      "\n",
      "         walkDistance  weaponsAcquired  winPoints  winPlacePerc  \n",
      "2744604           0.0                0          0           NaN  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Does the data have missing values now? Ans:False\n",
      "After preprocessing, the count of each match type is:\n",
      "matchType\n",
      "duo      1310282\n",
      "solo      718704\n",
      "squad    2382712\n",
      "dtype: int64\n",
      "{0: 'duo', 1: 'solo', 2: 'squad'}\n",
      "Below are metrics for Linear Regression Model of mixed match type\n",
      "MAE: 0.08326661073784998\n",
      "MSE: 0.012753514556163352\n",
      "R-Score: 0.8620232327775431\n",
      "Below are metrics for Linear Regression Model of solo match type\n",
      "MAE: 0.0827740127234431\n",
      "MSE: 0.011451254229496577\n",
      "R-Score: 0.875564197590103\n",
      "Below are metrics for Linear Regression Model of duo match type\n",
      "MAE: 0.06613708620500386\n",
      "MSE: 0.009253880494369544\n",
      "R-Score: 0.8957125771397122\n",
      "Below are metrics for Linear Regression Model of squad match type\n",
      "MAE: 0.09512095267854814\n",
      "MSE: 0.016212990759812303\n",
      "R-Score: 0.8244786916878496\n",
      "Average metrics over 3 sub-models is as follow\n",
      "Average MAE:0.0813440172023317, Average MSE:0.012306041827892808, Average R-Score:0.8652518221392217\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #Load data\n",
    "    FILE_LOCATION = 'train_V2.csv'\n",
    "    data_df = load_df(FILE_LOCATION)\n",
    "    \n",
    "    #Evaluate the data\n",
    "    evaluate(data_df)\n",
    "    \n",
    "    #Preprocess the data\n",
    "    data_preprocessed = preprocess(data_df)\n",
    "\n",
    "    #print(data_preprocessed[:,12])\n",
    "    \n",
    "    #Partition the data\n",
    "    DATASET_SIZE_PER_TYPE = 2000\n",
    "    X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad = partition(data_preprocessed,DATASET_SIZE_PER_TYPE)\n",
    "    #print(X_all.shape, y_all.shape, X_solo.shape, y_solo.shape, X_duo.shape, y_duo.shape, X_squad.shape, y_squad.shape)\n",
    "    \n",
    "    #Traina and test baseline LinearRegression\n",
    "    train_test_lin_reg(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad)\n",
    "    \n",
    "    #Traina and test random forest\n",
    "    #train_test_random_forest(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad)\n",
    "    \n",
    "    #Traina and test neural network\n",
    "    #train_test_nn(X_all, y_all, X_solo, y_solo, X_duo, y_duo, X_squad, y_squad)\n",
    "    \n",
    "    #draw graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
